{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edade85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import torch.nn.init as init\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.utils as torch_utils\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils import *\n",
    "from train_test_split import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da9c4c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r'dataloaders_AT_pretrain_3d_rev.pkl'\n",
    "with open(file_path, 'rb') as f:\n",
    "    train_dataloader, val_dataloader = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19dda3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from VAEres3d_mri_unsuper import VAE, VAE_Loss\n",
    "import math\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "from utils import *\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_survlosses = []\n",
    "val_survlosses = []\n",
    "\n",
    "beta = 1\n",
    "latent_dim = 256 \n",
    "red = 1\n",
    "drop = 0.0\n",
    "num_epochs = 500\n",
    "best_loss = float('inf') \n",
    "no_improvement_counter = 0\n",
    "early_stopping_patience = 10\n",
    "checkpoint_interval = 1\n",
    "checkpoint_counter = 0\n",
    "early_stopping_activate = True\n",
    "vae = VAE(latent_dim, red, drop).to(device)\n",
    "vae_loss_fn = VAE_Loss(beta).to(device)\n",
    "optimizer = optim.Adam(vae.parameters(), lr=0.00001)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', cooldown = 2, factor=0.1, patience=5, verbose=True)\n",
    "vae.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "    total_kl_loss = 0.0\n",
    "    vae.train() \n",
    "    for i, batch in enumerate(train_dataloader):\n",
    "        inputs = batch[0].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        x_recon, z, mu, log_var  = vae(inputs)\n",
    "        loss, _, kl_loss = vae_loss_fn(x_recon, inputs, mu, log_var)\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(vae.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "        total_loss, total_kl_loss = update_total_losses_unsuper(\n",
    "            total_loss, total_kl_loss, loss, kl_loss\n",
    "        )\n",
    "\n",
    "    avg_loss, avg_kl_loss = calculate_average_losses_unsuper(\n",
    "        total_loss, total_kl_loss, train_dataloader\n",
    "    )\n",
    "    \n",
    "    # Validation loop\n",
    "    vae.eval() \n",
    "    with torch.no_grad():\n",
    "        total_val_loss = 0.0\n",
    "        total_val_kl = 0.0\n",
    "        for val_batch in val_dataloader:\n",
    "            val_inputs = val_batch[0].to(device)\n",
    "            val_x_recon, val_z, val_mu, val_log_var = vae(val_inputs)\n",
    "            val_loss, _, val_kl_loss = vae_loss_fn(val_x_recon, val_inputs, val_mu, val_log_var)\n",
    "\n",
    "            total_val_loss, total_val_kl = update_total_losses_unsuper(total_val_loss, total_val_kl, val_loss, val_kl_loss)\n",
    "            \n",
    "            avg_val_loss, avg_val_kl_loss = calculate_average_losses_unsuper(total_val_loss, total_val_kl, val_dataloader)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Rec.T {avg_loss:.0f}, Rec.V: {avg_val_loss:.0f}, KL.T: {avg_kl_loss:.2f}, KL.V: {avg_val_kl_loss:.2f}\")\n",
    "        append_losses_unsuper(train_losses, val_losses, avg_loss, avg_val_loss)\n",
    "        scheduler_on_loss = avg_val_loss\n",
    "        scheduler.step(scheduler_on_loss)\n",
    "        \n",
    "        if scheduler_on_loss < best_loss:\n",
    "            best_loss = scheduler_on_loss\n",
    "            no_improvement_counter = 0\n",
    "        else:\n",
    "            no_improvement_counter += 1\n",
    "            if no_improvement_counter >= early_stopping_patience:\n",
    "                print(f\"Early stopping at epoch {epoch+1} due to no improvement in validation loss.\")\n",
    "                break\n",
    "                \n",
    "        save_checkpoint_intraining(\n",
    "            epoch, vae, optimizer, best_loss, checkpoint_folder, checkpoint_interval, checkpoint_counter, active=False)\n",
    "    vae.train()\n",
    "    \n",
    "plot_losses_unsuper(train_losses, val_losses)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1282a6",
   "metadata": {},
   "source": [
    "# Save weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "238c71e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a directory to save the final model weights\n",
    "final_model_dir = r\"\\\\WEIGHTS PRETRAIN\"\n",
    "os.makedirs(final_model_dir, exist_ok=True)\n",
    "final_model_path = os.path.join(final_model_dir, 'CMR-VAE.pt')\n",
    "torch.save(vae.state_dict(), final_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e2d7502",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt \n",
    "from mri_reconstruction_plottings import *\n",
    "%matplotlib inline\n",
    "from VAEres3d_mri_unsuper import *\n",
    "vae = VAE(latent_dim=256, red=1, drop=0).to(device)\n",
    "path_weights = r'\\\\CMR-VAE.pt'\n",
    "vae.load_state_dict(torch.load(path_weights))\n",
    "\n",
    "output_folder = r'\\\\Reconstruction examples'\n",
    "get_mri_reconstructions_unsuper_3d(vae, train_dataloader, num_epochs=5, number_of_examples=5, output_folder=output_folder, device='cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed83e2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mri_reconstructions_metrics(vae, train_dataloader, number_of_examples):\n",
    "    vae.to(device)\n",
    "    ssim_scores = []\n",
    "    psnr_scores = []\n",
    "    mse_scores = []\n",
    "    nrmse_scores = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(train_dataloader):\n",
    "            inputs = batch[0].to(device)\n",
    "           # if i > 5:\n",
    "           #     break\n",
    "            outputs, _, _, _, = vae(inputs)\n",
    "            for j in range(inputs.size(0)):\n",
    "                ssim_perpatient = []\n",
    "                psnr_perpatient = []\n",
    "                mse_perpatient = []\n",
    "                nrmse_perpatient = []\n",
    "                for slice in range(inputs.size(1)):\n",
    "                    original_image = inputs[j, slice, :, :, 0].cpu().numpy()\n",
    "                    reconstructed_image = outputs[j, slice, :, :, 0].cpu().numpy()\n",
    "\n",
    "                    ssim_value = ssim(original_image, reconstructed_image, data_range=reconstructed_image.max() - reconstructed_image.min())\n",
    "                    psnr_value = psnr(original_image, reconstructed_image, data_range=reconstructed_image.max() - reconstructed_image.min())\n",
    "                    mse_value = mean_squared_error(original_image, reconstructed_image)\n",
    "                    nrmse_value = normalized_root_mse(original_image, reconstructed_image)\n",
    "\n",
    "                    ssim_perpatient.append(ssim_value)\n",
    "                    psnr_perpatient.append(psnr_value)\n",
    "                    mse_perpatient.append(mse_value)\n",
    "                    if not (np.isinf(nrmse_value) or np.isnan(nrmse_value)):\n",
    "                        nrmse_perpatient.append(nrmse_value)\n",
    "\n",
    "                if len(nrmse_perpatient) > 0:\n",
    "                    ssim_scores.append(np.mean(ssim_perpatient))\n",
    "                    psnr_scores.append(np.mean(psnr_perpatient))\n",
    "                    mse_scores.append(np.mean(mse_perpatient))\n",
    "                    nrmse_scores.append(np.mean(nrmse_perpatient))\n",
    "\n",
    "    return {\n",
    "        \"Average SSIM\": np.mean(ssim_scores),\n",
    "        \"Std SSIM\": np.std(ssim_scores),\n",
    "        \"Average PSNR\": np.mean(psnr_scores),\n",
    "        \"Std PSNR\": np.std(psnr_scores),\n",
    "        \"Average MSE\": np.mean(mse_scores),\n",
    "        \"Std MSE\": np.std(mse_scores),\n",
    "        \"Average NRMSE\": np.mean(nrmse_scores),\n",
    "        \"Std NRMSE\": np.std(nrmse_scores)\n",
    "    }\n",
    "\n",
    "# Call the function with your VAE, data loader, and other parameters\n",
    "metrics = get_mri_reconstructions_metrics(vae, train_dataloader, 5)\n",
    "print(\"Metrics:\")\n",
    "for key, value in metrics.items():\n",
    "    print(f\"{key}: {value:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
